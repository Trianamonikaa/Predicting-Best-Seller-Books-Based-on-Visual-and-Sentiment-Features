{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score,cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from contractions import CONTRACTIONS_DICT \n",
    "from Convert_Negation import CONVERT_NEGATION\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NER(review):\n",
    "    for i in range(len(review)):\n",
    "        text = review.Review.iloc[i]\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "            for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "                if hasattr(chunk, 'label') and chunk.label:\n",
    "                    if chunk.label() == 'ORGANIZATION' or  chunk.label() == 'PERSON' or  chunk.label() == 'DATE' or  chunk.label() == 'LOCATION':\n",
    "                        name_value = ' '.join(child[0] for child in chunk.leaves())\n",
    "                        text = text.replace(name_value, \"\")\n",
    "                        review.Review.iloc[i] = text\n",
    "    return review\n",
    "\n",
    "def case_folding(review):\n",
    "    for i in range(len(review)):\n",
    "        text = review.Review[i].lower()\n",
    "        review.Review.iloc[i] = text \n",
    "    return review\n",
    "\n",
    "def expand_contraction(review):\n",
    "    contractions_re = re.compile('(%s)' % '|'.join(CONTRACTIONS_DICT.keys()))\n",
    "    d = {}\n",
    "    index=0\n",
    "    for i in review.Review:\n",
    "        text = i\n",
    "        def replace(match):\n",
    "            return CONTRACTIONS_DICT[match.group(0)]\n",
    "        text = contractions_re.sub(replace, text)\n",
    "        #review = review.replace(text,\"\")\n",
    "        review.Review[index] = text\n",
    "        index+=1\n",
    "    return review\n",
    "\n",
    "def convert_negation(review):\n",
    "    convertNegation_re = re.compile('(%s)' % '|'.join(CONVERT_NEGATION.keys()))\n",
    "    d = {}\n",
    "    index=0\n",
    "    for i in review.Review:\n",
    "        text = i\n",
    "        def replace(match):\n",
    "            return CONVERT_NEGATION[match.group(0)]\n",
    "        text = convertNegation_re.sub(replace, text)\n",
    "        review.Review[index] = text\n",
    "        index+=1\n",
    "    return review\n",
    "\n",
    "def remove_punctuation(review):\n",
    "    remove = string.punctuation\n",
    "    for i in range(len(review)):\n",
    "        for kata in remove:\n",
    "            text = review.Review[i].replace(kata,\"\")\n",
    "            review.Review.iloc[i] = text \n",
    "    return review\n",
    "\n",
    "def stop_removal(review):\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    cachedStopWords = set(stopwords.words(\"english\"))\n",
    "    for i in range(len(review)):\n",
    "        text = review.Review.iloc[i]\n",
    "        teks =\" \".join([word for word in text.split() if word not in cachedStopWords])\n",
    "        review.Review.iloc[i] = teks\n",
    "    return review\n",
    "\n",
    "def stemming(review):\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(review)):\n",
    "        text = review.Review.iloc[i]\n",
    "        text = ps.stem(text)\n",
    "        review.Review.iloc[i] = text\n",
    "    return review\n",
    "\n",
    "def lemmatization (review):\n",
    "    lm = WordNetLemmatizer()\n",
    "    for i in range(len(review)):\n",
    "        text = review.Review.iloc[i]\n",
    "        text = lm.lemmatize(text)\n",
    "        review.Review.iloc[i] = text\n",
    "    return review\n",
    "\n",
    "def preprocessing_data(review):\n",
    "    hasil_ner = NER(review)\n",
    "    hasil_case_folding = case_folding(hasil_ner)\n",
    "    hasil_convert_negation = convert_negation(hasil_case_folding)\n",
    "    hasil_expand = expand_contraction(hasil_convert_negation)\n",
    "    hasil_remove_punctuation = remove_punctuation(hasil_expand)\n",
    "    hasil_stop_removal = stop_removal(hasil_remove_punctuation)\n",
    "    hasil_stemming = stemming( hasil_stop_removal)\n",
    "    hasil_lemmatization = lemmatization(hasil_stemming)\n",
    "    return hasil_lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### load SVM model for klasifikasi\n",
    "filename1= 'model_sentimen.pkl'\n",
    "loaded_model = pickle.load(open(filename1, 'rb'))\n",
    "# ##########################################################################################################\n",
    "#### load SVM feature for klasifikasi\n",
    "filename1='feature.pkl'\n",
    "loaded_feature = pickle.load(open(filename1, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_review_buku = pd.read_excel('E:/_KEPERLUAN FINAL TA/TASI-14_REVISI_FIKS/data_review/Data_review_buku.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buku</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>disgusted author’s shameless attempt use trage...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>familiar tragedy found writing tragedy superfici</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sad see authors book taken personal stories su...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>would write garbag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>highly doubt would slit anyones throat drink b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sad wanted make quick buck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>bad read trash father survivor tragedy publish...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>disrespectful soldi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>read one book year on</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>beg youget hands copy book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Buku                                             Review  Rating  \\\n",
       "0     1  disgusted author’s shameless attempt use trage...     2.0   \n",
       "1     1   familiar tragedy found writing tragedy superfici     1.0   \n",
       "2     1  sad see authors book taken personal stories su...     1.0   \n",
       "3     2                                 would write garbag     1.0   \n",
       "4     2  highly doubt would slit anyones throat drink b...     1.0   \n",
       "5     2                         sad wanted make quick buck     1.0   \n",
       "6     2  bad read trash father survivor tragedy publish...     1.0   \n",
       "7     2                                disrespectful soldi     1.0   \n",
       "8     3                              read one book year on     5.0   \n",
       "9     3                         beg youget hands copy book     5.0   \n",
       "\n",
       "      Kategori  \n",
       "0  Best Seller  \n",
       "1  Best Seller  \n",
       "2  Best Seller  \n",
       "3  Best Seller  \n",
       "4  Best Seller  \n",
       "5  Best Seller  \n",
       "6  Best Seller  \n",
       "7  Best Seller  \n",
       "8  Best Seller  \n",
       "9  Best Seller  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review_buku.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1386, 1068)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best  = len([x for x in data_review_buku['Kategori'] if x == 'Best Seller'])\n",
    "non_best = len([x for x in data_review_buku['Kategori'] if x == 'Non Best Seller'])\n",
    "\n",
    "best, non_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gloria Hutauruk\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Gloria Hutauruk\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Gloria Hutauruk\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data_clean_review_buku = preprocessing_data(data_review_buku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gloria Hutauruk\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buku</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>disgusted author s shameless attempt use trage...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>familiar tragedy found writing tragedy superfici</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sad see authors book taken personal stories su...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>would write garbag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>highly doubt would slit anyones throat drink b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sad wanted make quick buck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>bad read trash father survivor tragedy publish...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>disrespectful soldi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>read one book year on</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>beg youget hands copy book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Buku                                             Review  Rating  \\\n",
       "0     1  disgusted author s shameless attempt use trage...     2.0   \n",
       "1     1   familiar tragedy found writing tragedy superfici     1.0   \n",
       "2     1  sad see authors book taken personal stories su...     1.0   \n",
       "3     2                                 would write garbag     1.0   \n",
       "4     2  highly doubt would slit anyones throat drink b...     1.0   \n",
       "5     2                         sad wanted make quick buck     1.0   \n",
       "6     2  bad read trash father survivor tragedy publish...     1.0   \n",
       "7     2                                disrespectful soldi     1.0   \n",
       "8     3                              read one book year on     5.0   \n",
       "9     3                         beg youget hands copy book     5.0   \n",
       "\n",
       "      Kategori  \n",
       "0  Best Seller  \n",
       "1  Best Seller  \n",
       "2  Best Seller  \n",
       "3  Best Seller  \n",
       "4  Best Seller  \n",
       "5  Best Seller  \n",
       "6  Best Seller  \n",
       "7  Best Seller  \n",
       "8  Best Seller  \n",
       "9  Best Seller  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern=r'[^a-zA-Z]'\n",
    "\n",
    "for i in range(len(data_clean_review_buku)):\n",
    "    data_clean_review_buku['Review'].iloc[i] = re.sub(pattern,' ', data_clean_review_buku['Review'].iloc[i], flags=re.MULTILINE)\n",
    "data_clean_review_buku.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasil_preprocessing = data_clean_review_buku.to_excel('datareviewbuku_after_preproced.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean_review = pd.read_excel('E:/_KEPERLUAN FINAL TA/TASI-14_REVISI_FIKS/datareviewbuku_after_preproced.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buku</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>disgusted author s shameless attempt use trage...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>familiar tragedy found writing tragedy superfici</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sad see authors book taken personal stories su...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>would write garbag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>highly doubt would slit anyones throat drink b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sad wanted make quick buck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>bad read trash father survivor tragedy publish...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>disrespectful soldi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>read one book year on</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>beg youget hands copy book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>enjoy history fascinating extremely well writt...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>probably one best books ever read story unknow...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>canbad one without becoming emotionally involv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>feel men felt difficult process emot</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>enjoyed captivating thing ever read</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>life struggle need fight every day according mean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>version type small difficult read</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>really feel like book changed life good great</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>small font surprised disappointed open book fi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>recommend anyone purchas</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>sure completely buy theories second half book</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>book easy read good provoking thought</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>disappointed com</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>boring drag</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>worth reading till end camp lif</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>got lost theory story told</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>book regular s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>beginning story incredible entire second half ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>book like narrative mans struggle nazi concent...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>good book thought I get hyp</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>695</td>\n",
       "      <td>inspiring book first heard book read devot</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>696</td>\n",
       "      <td>book immediately captured interest author s gi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>696</td>\n",
       "      <td>great book recommended friend started reading ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>696</td>\n",
       "      <td>really enjoyed reading author able portray lov...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>696</td>\n",
       "      <td>jesus lover book misrepres</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>697</td>\n",
       "      <td>would bought book boss insisted read staff boo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>697</td>\n",
       "      <td>disappointed book</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>697</td>\n",
       "      <td>book crazy redundant fan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>697</td>\n",
       "      <td>bad book</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>697</td>\n",
       "      <td>want know lead successfully starting point</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>697</td>\n",
       "      <td>okrs designed simply efficiently capture essen...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>698</td>\n",
       "      <td>tell book worth</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>698</td>\n",
       "      <td>great read applicable everyth</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>698</td>\n",
       "      <td>considering many successful companies individu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>698</td>\n",
       "      <td>save money google book lengthy blog post articl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>698</td>\n",
       "      <td>beware sync vers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>699</td>\n",
       "      <td>worst book I ever purchas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>699</td>\n",
       "      <td>real knee slapper book disgust</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>699</td>\n",
       "      <td>book wonderful easily digestible summation sta...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>699</td>\n",
       "      <td>really doubt people hurry understand book enti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>699</td>\n",
       "      <td>explanations easily entice one seek informatio...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>699</td>\n",
       "      <td>intend look another book thank you</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>700</td>\n",
       "      <td>would recommend anyone astronomy science gener</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>700</td>\n",
       "      <td>text disjointed rambling would benefited illustr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>700</td>\n",
       "      <td>highly disappoint</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>700</td>\n",
       "      <td>bought hopes educating efficiently book confus...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>700</td>\n",
       "      <td>lame book gives generic overviews really expla...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>700</td>\n",
       "      <td>enjoy reading book expected easier read meet e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>700</td>\n",
       "      <td>l started marking recipes l wanted try first l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>700</td>\n",
       "      <td>highly recommend w   cookbook</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Non Best Seller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Buku                                             Review  Rating  \\\n",
       "0        1  disgusted author s shameless attempt use trage...     2.0   \n",
       "1        1   familiar tragedy found writing tragedy superfici     1.0   \n",
       "2        1  sad see authors book taken personal stories su...     1.0   \n",
       "3        2                                 would write garbag     1.0   \n",
       "4        2  highly doubt would slit anyones throat drink b...     1.0   \n",
       "5        2                         sad wanted make quick buck     1.0   \n",
       "6        2  bad read trash father survivor tragedy publish...     1.0   \n",
       "7        2                                disrespectful soldi     1.0   \n",
       "8        3                              read one book year on     5.0   \n",
       "9        3                         beg youget hands copy book     5.0   \n",
       "10       3  enjoy history fascinating extremely well writt...     5.0   \n",
       "11       3  probably one best books ever read story unknow...     5.0   \n",
       "12       3     canbad one without becoming emotionally involv     5.0   \n",
       "13       4               feel men felt difficult process emot     5.0   \n",
       "14       4                enjoyed captivating thing ever read     3.0   \n",
       "15       4  life struggle need fight every day according mean     3.0   \n",
       "16       4                  version type small difficult read     3.0   \n",
       "17       5      really feel like book changed life good great     3.0   \n",
       "18       5  small font surprised disappointed open book fi...     2.0   \n",
       "19       5                           recommend anyone purchas     2.0   \n",
       "20       6      sure completely buy theories second half book     3.0   \n",
       "21       6              book easy read good provoking thought     3.0   \n",
       "22       6                                   disappointed com     2.0   \n",
       "23       6                                        boring drag     2.0   \n",
       "24       7                    worth reading till end camp lif     3.0   \n",
       "25       7                         got lost theory story told     3.0   \n",
       "26       7                                     book regular s     2.0   \n",
       "27       8  beginning story incredible entire second half ...     3.0   \n",
       "28       8  book like narrative mans struggle nazi concent...     3.0   \n",
       "29       8                        good book thought I get hyp     2.0   \n",
       "...    ...                                                ...     ...   \n",
       "2424   695         inspiring book first heard book read devot     5.0   \n",
       "2425   696  book immediately captured interest author s gi...     5.0   \n",
       "2426   696  great book recommended friend started reading ...     5.0   \n",
       "2427   696  really enjoyed reading author able portray lov...     5.0   \n",
       "2428   696                         jesus lover book misrepres     1.0   \n",
       "2429   697  would bought book boss insisted read staff boo...     1.0   \n",
       "2430   697                                  disappointed book     1.0   \n",
       "2431   697                           book crazy redundant fan     1.0   \n",
       "2432   697                                           bad book     1.0   \n",
       "2433   697         want know lead successfully starting point     5.0   \n",
       "2434   697  okrs designed simply efficiently capture essen...     5.0   \n",
       "2435   698                                    tell book worth     5.0   \n",
       "2436   698                      great read applicable everyth     5.0   \n",
       "2437   698  considering many successful companies individu...     5.0   \n",
       "2438   698    save money google book lengthy blog post articl     1.0   \n",
       "2439   698                                   beware sync vers     1.0   \n",
       "2440   699                          worst book I ever purchas     1.0   \n",
       "2441   699                     real knee slapper book disgust     1.0   \n",
       "2442   699  book wonderful easily digestible summation sta...     5.0   \n",
       "2443   699  really doubt people hurry understand book enti...     5.0   \n",
       "2444   699  explanations easily entice one seek informatio...     5.0   \n",
       "2445   699                intend look another book thank you      5.0   \n",
       "2446   700     would recommend anyone astronomy science gener     5.0   \n",
       "2447   700   text disjointed rambling would benefited illustr     1.0   \n",
       "2448   700                                  highly disappoint     1.0   \n",
       "2449   700  bought hopes educating efficiently book confus...     1.0   \n",
       "2450   700  lame book gives generic overviews really expla...     1.0   \n",
       "2451   700  enjoy reading book expected easier read meet e...     1.0   \n",
       "2452   700  l started marking recipes l wanted try first l...     5.0   \n",
       "2453   700                      highly recommend w   cookbook     5.0   \n",
       "\n",
       "             Kategori  \n",
       "0         Best Seller  \n",
       "1         Best Seller  \n",
       "2         Best Seller  \n",
       "3         Best Seller  \n",
       "4         Best Seller  \n",
       "5         Best Seller  \n",
       "6         Best Seller  \n",
       "7         Best Seller  \n",
       "8         Best Seller  \n",
       "9         Best Seller  \n",
       "10        Best Seller  \n",
       "11        Best Seller  \n",
       "12        Best Seller  \n",
       "13        Best Seller  \n",
       "14        Best Seller  \n",
       "15        Best Seller  \n",
       "16        Best Seller  \n",
       "17        Best Seller  \n",
       "18        Best Seller  \n",
       "19        Best Seller  \n",
       "20        Best Seller  \n",
       "21        Best Seller  \n",
       "22        Best Seller  \n",
       "23        Best Seller  \n",
       "24        Best Seller  \n",
       "25        Best Seller  \n",
       "26        Best Seller  \n",
       "27        Best Seller  \n",
       "28        Best Seller  \n",
       "29        Best Seller  \n",
       "...               ...  \n",
       "2424  Non Best Seller  \n",
       "2425  Non Best Seller  \n",
       "2426  Non Best Seller  \n",
       "2427  Non Best Seller  \n",
       "2428  Non Best Seller  \n",
       "2429  Non Best Seller  \n",
       "2430  Non Best Seller  \n",
       "2431  Non Best Seller  \n",
       "2432  Non Best Seller  \n",
       "2433  Non Best Seller  \n",
       "2434  Non Best Seller  \n",
       "2435  Non Best Seller  \n",
       "2436  Non Best Seller  \n",
       "2437  Non Best Seller  \n",
       "2438  Non Best Seller  \n",
       "2439  Non Best Seller  \n",
       "2440  Non Best Seller  \n",
       "2441  Non Best Seller  \n",
       "2442  Non Best Seller  \n",
       "2443  Non Best Seller  \n",
       "2444  Non Best Seller  \n",
       "2445  Non Best Seller  \n",
       "2446  Non Best Seller  \n",
       "2447  Non Best Seller  \n",
       "2448  Non Best Seller  \n",
       "2449  Non Best Seller  \n",
       "2450  Non Best Seller  \n",
       "2451  Non Best Seller  \n",
       "2452  Non Best Seller  \n",
       "2453  Non Best Seller  \n",
       "\n",
       "[2454 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_data = []\n",
    "for index, row in data_clean_review_buku.iterrows():\n",
    "    arr_data.append([row['Buku'],row['Kategori']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extraction = loaded_feature.transform(data_clean_review_buku.Review.values.astype('U'))\n",
    "predicted = loaded_model.predict_proba(feature_extraction)       \n",
    "score =[]\n",
    "for i in predicted:\n",
    "    score.append(i)\n",
    "\n",
    "sentimen_score = []\n",
    "for i in range(len(score)):\n",
    "    sentimen_score.append(score [i][1])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentimen_score)):\n",
    "    data = arr_data[i]\n",
    "    data.append(sentimen_score[i])\n",
    "    arr_data[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_book = ''\n",
    "i = 0\n",
    "for j in range(len(arr_data)):\n",
    "    temp_score = 0.0\n",
    "    if(temp_book == arr_data[j][0]):\n",
    "        i+=1\n",
    "    else:\n",
    "        for k in range(j-i, j):\n",
    "            temp_score +=arr_data[k][2]\n",
    "        if(temp_score > 0.0):\n",
    "            data = arr_data[j-1]\n",
    "            data.append(temp_score/i)\n",
    "            arr_data[j-1] = data\n",
    "        i = 1\n",
    "    if(j == len(arr_data)-1):\n",
    "        for k in range(j-i+1, j+1):\n",
    "            temp_score +=arr_data[k][2]\n",
    "        if(temp_score > 0.0):\n",
    "            data = arr_data[j]\n",
    "            data.append(temp_score/i)\n",
    "            arr_data[j] = data\n",
    "    temp_book = arr_data[j][0]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fitur_sentimen = [x for x in arr_data if(len(x)>3)]\n",
    "for i in range(len(data_fitur_sentimen)):\n",
    "    data = data_fitur_sentimen[i][:2]\n",
    "    data.append(data_fitur_sentimen[i][3])\n",
    "    data_fitur_sentimen[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitur_sentimen = pd.DataFrame(data_fitur_sentimen)\n",
    "# a.columns = ['precision','recall','f1-score']\n",
    "fitur_sentimen.columns = ['Buku','Kategori','FiturSentimen']\n",
    "# label = fitur_sentimen[1]\n",
    "# score = fitur_sentimen[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_encoder = LabelEncoder()\n",
    "y = category_encoder.fit_transform(fitur_sentimen['Kategori'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitur_sentimen = np.array(score)\n",
    "fitur_sentimen = fitur_sentimen.reshape(-1, 1)\n",
    "C = 1.0  # SVM regularization parameter\n",
    "model_sentimen = SVC(kernel='linear', C=C)\n",
    "\n",
    "p = cross_val_score(model_sentimen, fitur_sentimen, y, cv=10, scoring= 'precision')\n",
    "precision_sentimen_feature = (sum(p)/len(p))\n",
    "r = cross_val_score(model_sentimen, fitur_sentimen, y, cv=10, scoring='recall')\n",
    "recall_sentimen_feature = (sum(r)/len(r)) \n",
    "f = cross_val_score(model_sentimen, fitur_sentimen, y, cv=10, scoring='f1')\n",
    "f_measure_sentimen_feature = (sum(f)/len(f)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53046522896468551, 0.39714285714285713, 0.45167354317756009)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_sentimen_feature,recall_sentimen_feature,f_measure_sentimen_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "myFile = open('data_fitur_sentimen.csv', 'w')\n",
    "with myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(fitur_sentimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
